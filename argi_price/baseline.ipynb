{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 농산물 가격 예측을 위한 AI 모델 개발 \n",
    "- '2024 농산물 가격 예측 AI 경진대회'는 데이터와 AI 기술을 활용하여 농산물 가격 예측 능력을 향상시키는 것을 목표로 합니다.<br>  이 대회는 농업 분야의 복잡한 시계열 데이터를 효율적으로 분석하고 예측할 수 있는 AI 알고리즘 개발에 초점을 맞추고 있습니다. <br> <br>\n",
    "- 이 대회의 궁극적 목적은 참가자들의 시계열 데이터 분석 및 예측 역량을 강화하고, <br> AI 기술이 실제 농산물 가격 예측과 관련 정책 결정에 어떻게 기여할 수 있는지 탐구하는 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from types import SimpleNamespace\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"epoch\": 30,\n",
    "    \"batch_size\": 64,\n",
    "    \"hidden_size\": 64,\n",
    "    \"num_layers\": 2,\n",
    "    \"output_size\": 3\n",
    "}\n",
    "\n",
    "CFG = SimpleNamespace(**config)\n",
    "\n",
    "품목_리스트 = ['건고추', '사과', '감자', '배', '깐마늘(국산)', '무', '상추', '배추', '양파', '대파']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function for Feature Engineering\n",
    "- 타겟의 필터 조건을 제외한 메타데이터의 필터 조건은 참가자들 각자의 기준에 맞춰 자유롭게 사용가능 \n",
    "- 밑의 필터 조건은 임의로 제공하는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_data(raw_file, 산지공판장_file, 전국도매_file, 품목명, scaler=None):\n",
    "    raw_data = pd.read_csv(raw_file)\n",
    "    산지공판장 = pd.read_csv(산지공판장_file)\n",
    "    전국도매 = pd.read_csv(전국도매_file)\n",
    "\n",
    "    # 타겟 및 메타데이터 필터 조건 정의\n",
    "    conditions = {\n",
    "    '감자': {\n",
    "        'target': lambda df: (df['품종명'] == '감자 수미') & (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['감자'], '품종명': ['수미'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['감자'], '품종명': ['수미']}\n",
    "    },\n",
    "    '건고추': {\n",
    "        'target': lambda df: (df['품종명'] == '화건') & (df['거래단위'] == '30 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': None, \n",
    "        '도매': None  \n",
    "    },\n",
    "    '깐마늘(국산)': {\n",
    "        'target': lambda df: (df['거래단위'] == '20 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['마늘'], '품종명': ['깐마늘'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['마늘'], '품종명': ['깐마늘']}\n",
    "    },\n",
    "    '대파': {\n",
    "        'target': lambda df: (df['품종명'] == '대파(일반)') & (df['거래단위'] == '1키로단') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['대파'], '품종명': ['대파(일반)'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['대파'], '품종명': ['대파(일반)']}\n",
    "    },\n",
    "    '무': {\n",
    "        'target': lambda df: (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['무'], '품종명': ['기타무'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['무'], '품종명': ['무']}\n",
    "    },\n",
    "    '배추': {\n",
    "        'target': lambda df: (df['거래단위'] == '10키로망대') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배추'], '품종명': ['쌈배추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배추'], '품종명': ['배추']}\n",
    "    },\n",
    "    '사과': {\n",
    "        'target': lambda df: (df['품종명'].isin(['홍로', '후지'])) & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['사과'], '품종명': ['후지'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['사과'], '품종명': ['후지']}\n",
    "    },\n",
    "    '상추': {\n",
    "        'target': lambda df: (df['품종명'] == '청') & (df['거래단위'] == '100 g') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['상추'], '품종명': ['청상추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['상추'], '품종명': ['청상추']}\n",
    "    },\n",
    "    '양파': {\n",
    "        'target': lambda df: (df['품종명'] == '양파') & (df['거래단위'] == '1키로') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['양파'], '품종명': ['기타양파'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['양파'], '품종명': ['양파(일반)']}\n",
    "    },\n",
    "    '배': {\n",
    "        'target': lambda df: (df['품종명'] == '신고') & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배'], '품종명': ['신고'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배'], '품종명': ['신고']}\n",
    "    }\n",
    "    }\n",
    "\n",
    "    # 타겟 데이터 필터링\n",
    "    raw_품목 = raw_data[raw_data['품목명'] == 품목명]\n",
    "    target_mask = conditions[품목명]['target'](raw_품목)\n",
    "    filtered_data = raw_품목[target_mask]\n",
    "\n",
    "    # # 다른 품종에 대한 파생변수 생성\n",
    "    # other_data = raw_품목[~target_mask]\n",
    "    # unique_combinations = other_data[['품종명', '거래단위', '등급']].drop_duplicates()\n",
    "    # for _, row in unique_combinations.iterrows():\n",
    "    #     품종명, 거래단위, 등급 = row['품종명'], row['거래단위'], row['등급']\n",
    "    #     mask = (other_data['품종명'] == 품종명) & (other_data['거래단위'] == 거래단위) & (other_data['등급'] == 등급)\n",
    "    #     temp_df = other_data[mask]\n",
    "    #     for col in ['평년 평균가격(원)', '평균가격(원)']:\n",
    "    #         new_col_name = f'{품종명}_{거래단위}_{등급}_{col}'\n",
    "    #         filtered_data = filtered_data.merge(temp_df[['시점', col]], on='시점', how='left', suffixes=('', f'_{new_col_name}'))\n",
    "    #         filtered_data.rename(columns={f'{col}_{new_col_name}': new_col_name}, inplace=True)\n",
    "\n",
    "\n",
    "    # # 공판장 데이터 처리\n",
    "    # if conditions[품목명]['공판장']:\n",
    "    #     filtered_공판장 = 산지공판장\n",
    "    #     for key, value in conditions[품목명]['공판장'].items():\n",
    "    #         filtered_공판장 = filtered_공판장[filtered_공판장[key].isin(value)]\n",
    "        \n",
    "    #     filtered_공판장 = filtered_공판장.add_prefix('공판장_').rename(columns={'공판장_시점': '시점'})\n",
    "    #     filtered_data = filtered_data.merge(filtered_공판장, on='시점', how='left')\n",
    "\n",
    "    # # 도매 데이터 처리\n",
    "    # if conditions[품목명]['도매']:\n",
    "    #     filtered_도매 = 전국도매\n",
    "    #     for key, value in conditions[품목명]['도매'].items():\n",
    "    #         filtered_도매 = filtered_도매[filtered_도매[key].isin(value)]\n",
    "        \n",
    "    #     filtered_도매 = filtered_도매.add_prefix('도매_').rename(columns={'도매_시점': '시점'})\n",
    "    #     filtered_data = filtered_data.merge(filtered_도매, on='시점', how='left')\n",
    "\n",
    "    # 수치형 컬럼 처리\n",
    "    numeric_columns = filtered_data.select_dtypes(include=[np.number]).columns\n",
    "    numeric_columns = [col for col in numeric_columns if col != '평년 평균가격(원)']\n",
    "    filtered_data = filtered_data[['시점'] + list(numeric_columns)]\n",
    "    filtered_data[numeric_columns] = filtered_data[numeric_columns].fillna(0)\n",
    "\n",
    "    # # 정규화 적용\n",
    "    # if scaler is None:\n",
    "    #     scaler = MinMaxScaler()\n",
    "    #     filtered_data[numeric_columns] = scaler.fit_transform(filtered_data[numeric_columns])\n",
    "    # else:\n",
    "    #     filtered_data[numeric_columns] = scaler.transform(filtered_data[numeric_columns])\n",
    "\n",
    "    return filtered_data, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품목: 깐마늘(국산)\n",
      "            시점        평균가격(원)\n",
      "7200  201801상순  130666.666667\n",
      "7201  201801중순  130600.000000\n",
      "7202  201801하순  130600.000000\n",
      "7203  201802상순  134614.500000\n",
      "7204  201802중순  137100.000000\n",
      "...        ...            ...\n",
      "7339  202111중순  167200.000000\n",
      "7340  202111하순  169100.000000\n",
      "7341  202112상순  169100.000000\n",
      "7342  202112중순  169100.000000\n",
      "7343  202112하순  168033.500000\n",
      "\n",
      "[144 rows x 2 columns]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "i = 4\n",
    "train_data, scaler = process_data(\"./data/train/train.csv\", \n",
    "                            \"./data/train/meta/TRAIN_산지공판장_2018-2021.csv\", \n",
    "                            \"./data/train/meta/TRAIN_전국도매_2018-2021.csv\", \n",
    "                            품목_리스트[i])\n",
    "print(\"품목:\", 품목_리스트[i])\n",
    "print(train_data)\n",
    "print(scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgriculturePriceDataset(Dataset):\n",
    "    def __init__(self, dataframe, window_size=9, prediction_length=3, is_test=False):\n",
    "        self.data = dataframe\n",
    "        self.window_size = window_size\n",
    "        self.prediction_length = prediction_length\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        self.price_column = [col for col in self.data.columns if '평균가격(원)' in col and len(col.split('_')) == 1][0]\n",
    "        self.numeric_columns = self.data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        \n",
    "        self.sequences = []\n",
    "        if not self.is_test:\n",
    "            for i in range(len(self.data) - self.window_size - self.prediction_length + 1):\n",
    "                x = self.data[self.numeric_columns].iloc[i:i+self.window_size].values\n",
    "                y = self.data[self.price_column].iloc[i+self.window_size:i+self.window_size+self.prediction_length].values\n",
    "                self.sequences.append((x, y))\n",
    "        else:\n",
    "            self.sequences = [self.data[self.numeric_columns].values]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if not self.is_test:\n",
    "            x, y = self.sequences[idx]\n",
    "            return torch.FloatTensor(x), torch.FloatTensor(y)\n",
    "        else:\n",
    "            return torch.FloatTensor(self.sequences[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model Architecture and Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PricePredictionLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(PricePredictionLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)  \n",
    "\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f12ece502d4df9a41142c8e6917076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "품목 처리 중:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ty\\AppData\\Local\\Temp\\ipykernel_24352\\2844131541.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[numeric_columns] = filtered_data[numeric_columns].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train Loss: 434555.1875, Val Loss: 422590.1250\n",
      "Epoch 2/30, Train Loss: 431651.3438, Val Loss: 422590.1250\n",
      "Epoch 3/30, Train Loss: 431806.9062, Val Loss: 422590.1250\n",
      "Epoch 4/30, Train Loss: 433122.5000, Val Loss: 422590.1250\n",
      "Epoch 5/30, Train Loss: 432017.1250, Val Loss: 422590.1250\n",
      "Epoch 6/30, Train Loss: 433499.5000, Val Loss: 422590.0625\n",
      "Epoch 7/30, Train Loss: 433326.9688, Val Loss: 422590.0625\n",
      "Epoch 8/30, Train Loss: 432596.1875, Val Loss: 422590.0625\n",
      "Epoch 9/30, Train Loss: 431940.1562, Val Loss: 422590.0625\n",
      "Epoch 10/30, Train Loss: 433935.2344, Val Loss: 422590.0625\n",
      "Epoch 11/30, Train Loss: 434937.5469, Val Loss: 422590.0625\n",
      "Epoch 12/30, Train Loss: 431797.5000, Val Loss: 422590.0625\n",
      "Epoch 13/30, Train Loss: 432479.9688, Val Loss: 422590.0625\n",
      "Epoch 14/30, Train Loss: 433910.4531, Val Loss: 422590.0625\n",
      "Epoch 15/30, Train Loss: 434874.2969, Val Loss: 422590.0625\n",
      "Epoch 16/30, Train Loss: 434669.5625, Val Loss: 422590.0625\n",
      "Epoch 17/30, Train Loss: 435424.7344, Val Loss: 422590.0625\n",
      "Epoch 18/30, Train Loss: 433899.8750, Val Loss: 422590.0625\n",
      "Epoch 19/30, Train Loss: 434541.4688, Val Loss: 422590.0625\n",
      "Epoch 20/30, Train Loss: 433438.7188, Val Loss: 422590.0625\n",
      "Epoch 21/30, Train Loss: 435129.8125, Val Loss: 422590.0625\n",
      "Epoch 22/30, Train Loss: 432967.1250, Val Loss: 422590.0625\n",
      "Epoch 23/30, Train Loss: 434477.0312, Val Loss: 422590.0625\n",
      "Epoch 24/30, Train Loss: 434568.4688, Val Loss: 422590.0625\n",
      "Epoch 25/30, Train Loss: 434974.2812, Val Loss: 422590.0625\n",
      "Epoch 26/30, Train Loss: 434334.1250, Val Loss: 422590.0312\n",
      "Epoch 27/30, Train Loss: 434202.0938, Val Loss: 422590.0312\n",
      "Epoch 28/30, Train Loss: 432688.5469, Val Loss: 422590.0312\n",
      "Epoch 29/30, Train Loss: 432376.5625, Val Loss: 422590.0312\n",
      "Epoch 30/30, Train Loss: 433191.1562, Val Loss: 422589.9688\n",
      "Best Validation Loss for 건고추: 422589.9688\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da9459bb5444460a7919cc507aac308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "테스트 파일 추론 중:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ty\\AppData\\Local\\Temp\\ipykernel_24352\\2844131541.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[numeric_columns] = filtered_data[numeric_columns].fillna(0)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'min_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# 가격 열에 대해서만 inverse_transform 적용\u001b[39;00m\n\u001b[0;32m     68\u001b[0m price_scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m---> 69\u001b[0m price_scaler\u001b[38;5;241m.\u001b[39mmin_ \u001b[38;5;241m=\u001b[39m \u001b[43m품목별_scalers\u001b[49m\u001b[43m[\u001b[49m\u001b[43m품목명\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin_\u001b[49m[price_column_index]\n\u001b[0;32m     70\u001b[0m price_scaler\u001b[38;5;241m.\u001b[39mscale_ \u001b[38;5;241m=\u001b[39m 품목별_scalers[품목명]\u001b[38;5;241m.\u001b[39mscale_[price_column_index]\n\u001b[0;32m     71\u001b[0m predictions_original_scale \u001b[38;5;241m=\u001b[39m price_scaler\u001b[38;5;241m.\u001b[39minverse_transform(predictions_reshaped)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'min_'"
     ]
    }
   ],
   "source": [
    "품목별_predictions = {}\n",
    "품목별_scalers = {}\n",
    "\n",
    "pbar_outer = tqdm(품목_리스트, desc=\"품목 처리 중\", position=0)\n",
    "for 품목명 in pbar_outer:\n",
    "    pbar_outer.set_description(f\"품목별 전처리 및 모델 학습 -> {품목명}\")\n",
    "    train_data, scaler = process_data(\"./data/train/train.csv\", \n",
    "                              \"./data/train/meta/TRAIN_산지공판장_2018-2021.csv\", \n",
    "                              \"./data/train/meta/TRAIN_전국도매_2018-2021.csv\", \n",
    "                              품목명)\n",
    "    품목별_scalers[품목명] = scaler\n",
    "    dataset = AgriculturePriceDataset(train_data)\n",
    "\n",
    "    # 데이터를 train과 validation으로 분할\n",
    "    train_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_loader = DataLoader(train_data, CFG.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, CFG.batch_size, shuffle=False)\n",
    "\n",
    "    input_size = len(dataset.numeric_columns)\n",
    "    \n",
    "    model = PricePredictionLSTM(input_size, CFG.hidden_size, CFG.num_layers, CFG.output_size)\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), CFG.learning_rate)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "\n",
    "    for epoch in range(CFG.epoch):\n",
    "        train_loss = train_model(model, train_loader, criterion, optimizer, CFG.epoch)\n",
    "        val_loss = evaluate_model(model, val_loader, criterion)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f'models/best_model_{품목명}.pth')\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{CFG.epoch}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    print(f'Best Validation Loss for {품목명}: {best_val_loss:.4f}')\n",
    "    \n",
    "    품목_predictions = []\n",
    "\n",
    "    ### 추론 \n",
    "    pbar_inner = tqdm(range(25), desc=\"테스트 파일 추론 중\", position=1, leave=False)\n",
    "    for i in pbar_inner:\n",
    "        test_file = f\"./data/test/TEST_{i:02d}.csv\"\n",
    "        산지공판장_file = f\"./data/test/meta/TEST_산지공판장_{i:02d}.csv\"\n",
    "        전국도매_file = f\"./data/test/meta/TEST_전국도매_{i:02d}.csv\"\n",
    "        \n",
    "        test_data, _ = process_data(test_file, 산지공판장_file, 전국도매_file, 품목명, scaler=품목별_scalers[품목명])\n",
    "        test_dataset = AgriculturePriceDataset(test_data, is_test=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                output = model(batch)\n",
    "                predictions.append(output.numpy())\n",
    "        \n",
    "        predictions_array = np.concatenate(predictions)\n",
    "\n",
    "        # 예측값을 원래 스케일로 복원\n",
    "        price_column_index = test_data.columns.get_loc(test_dataset.price_column)\n",
    "        predictions_reshaped = predictions_array.reshape(-1, 1)\n",
    "        \n",
    "        # 가격 열에 대해서만 inverse_transform 적용\n",
    "        price_scaler = MinMaxScaler()\n",
    "        price_scaler.min_ = 품목별_scalers[품목명].min_[price_column_index]\n",
    "        price_scaler.scale_ = 품목별_scalers[품목명].scale_[price_column_index]\n",
    "        predictions_original_scale = price_scaler.inverse_transform(predictions_reshaped)\n",
    "        #print(predictions_original_scale)\n",
    "        \n",
    "        if np.isnan(predictions_original_scale).any():\n",
    "            pbar_inner.set_postfix({\"상태\": \"NaN\"})\n",
    "        else:\n",
    "            pbar_inner.set_postfix({\"상태\": \"정상\"})\n",
    "            품목_predictions.extend(predictions_original_scale.flatten())\n",
    "\n",
    "            \n",
    "    품목별_predictions[품목명] = 품목_predictions\n",
    "    pbar_outer.update(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           시점   감자  건고추  깐마늘(국산)   대파    무   배추   사과   상추   양파    배\n",
      "0  TEST_00+1순  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "1  TEST_00+2순  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "2  TEST_00+3순  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "3  TEST_01+1순  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
      "4  TEST_01+2순  0.0  0.0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('./data/submissionfiles/sample_submission.csv', encoding='utf-8')\n",
    "print(sample_submission.head(5))\n",
    "\n",
    "for 품목명, predictions in 품목별_predictions.items():\n",
    "    sample_submission[품목명] = predictions\n",
    "\n",
    "# 결과 저장\n",
    "sample_submission.to_csv('./data/submissionfiles/baseline_submission.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_eda(raw_file, 산지공판장_file, 전국도매_file, 품목명, scaler=None):\n",
    "    raw_data = pd.read_csv(raw_file)\n",
    "    산지공판장 = pd.read_csv(산지공판장_file)\n",
    "    전국도매 = pd.read_csv(전국도매_file)\n",
    "\n",
    "    # 타겟 및 메타데이터 필터 조건 정의\n",
    "    conditions = {\n",
    "    '감자': {\n",
    "        'target': lambda df: (df['품종명'] == '감자 수미') & (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['감자'], '품종명': ['수미'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['감자'], '품종명': ['수미']}\n",
    "    },\n",
    "    '건고추': {\n",
    "        'target': lambda df: (df['품종명'] == '화건') & (df['거래단위'] == '30 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': None, \n",
    "        '도매': None  \n",
    "    },\n",
    "    '깐마늘(국산)': {\n",
    "        'target': lambda df: (df['거래단위'] == '20 kg') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['마늘'], '품종명': ['깐마늘'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['마늘'], '품종명': ['깐마늘']}\n",
    "    },\n",
    "    '대파': {\n",
    "        'target': lambda df: (df['품종명'] == '대파(일반)') & (df['거래단위'] == '1키로단') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['대파'], '품종명': ['대파(일반)'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['대파'], '품종명': ['대파(일반)']}\n",
    "    },\n",
    "    '무': {\n",
    "        'target': lambda df: (df['거래단위'] == '20키로상자') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['무'], '품종명': ['기타무'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['무'], '품종명': ['무']}\n",
    "    },\n",
    "    '배추': {\n",
    "        'target': lambda df: (df['거래단위'] == '10키로망대') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배추'], '품종명': ['쌈배추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배추'], '품종명': ['배추']}\n",
    "    },\n",
    "    '사과': {\n",
    "        'target': lambda df: (df['품종명'].isin(['홍로', '후지'])) & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['사과'], '품종명': ['후지'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['사과'], '품종명': ['후지']}\n",
    "    },\n",
    "    '상추': {\n",
    "        'target': lambda df: (df['품종명'] == '청') & (df['거래단위'] == '100 g') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['상추'], '품종명': ['청상추'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['상추'], '품종명': ['청상추']}\n",
    "    },\n",
    "    '양파': {\n",
    "        'target': lambda df: (df['품종명'] == '양파') & (df['거래단위'] == '1키로') & (df['등급'] == '상'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['양파'], '품종명': ['기타양파'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['양파'], '품종명': ['양파(일반)']}\n",
    "    },\n",
    "    '배': {\n",
    "        'target': lambda df: (df['품종명'] == '신고') & (df['거래단위'] == '10 개') & (df['등급'] == '상품'),\n",
    "        '공판장': {'공판장명': ['*전국농협공판장'], '품목명': ['배'], '품종명': ['신고'], '등급명': ['상']},\n",
    "        '도매': {'시장명': ['*전국도매시장'], '품목명': ['배'], '품종명': ['신고']}\n",
    "    }\n",
    "    }\n",
    "\n",
    "    # 타겟 데이터 필터링\n",
    "    raw_품목 = raw_data[raw_data['품목명'] == 품목명]\n",
    "    target_mask = conditions[품목명]['target'](raw_품목)\n",
    "    filtered_data = raw_품목[target_mask]\n",
    "\n",
    "    # # 다른 품종에 대한 파생변수 생성\n",
    "    # other_data = raw_품목[~target_mask]\n",
    "    # unique_combinations = other_data[['품종명', '거래단위', '등급']].drop_duplicates()\n",
    "    # for _, row in unique_combinations.iterrows():\n",
    "    #     품종명, 거래단위, 등급 = row['품종명'], row['거래단위'], row['등급']\n",
    "    #     mask = (other_data['품종명'] == 품종명) & (other_data['거래단위'] == 거래단위) & (other_data['등급'] == 등급)\n",
    "    #     temp_df = other_data[mask]\n",
    "    #     for col in ['평년 평균가격(원)', '평균가격(원)']:\n",
    "    #         new_col_name = f'{품종명}_{거래단위}_{등급}_{col}'\n",
    "    #         filtered_data = filtered_data.merge(temp_df[['시점', col]], on='시점', how='left', suffixes=('', f'_{new_col_name}'))\n",
    "    #         filtered_data.rename(columns={f'{col}_{new_col_name}': new_col_name}, inplace=True)\n",
    "\n",
    "\n",
    "    # # 공판장 데이터 처리\n",
    "    # if conditions[품목명]['공판장']:\n",
    "    #     filtered_공판장 = 산지공판장\n",
    "    #     for key, value in conditions[품목명]['공판장'].items():\n",
    "    #         filtered_공판장 = filtered_공판장[filtered_공판장[key].isin(value)]\n",
    "        \n",
    "    #     filtered_공판장 = filtered_공판장.add_prefix('공판장_').rename(columns={'공판장_시점': '시점'})\n",
    "    #     filtered_data = filtered_data.merge(filtered_공판장, on='시점', how='left')\n",
    "\n",
    "    # # 도매 데이터 처리\n",
    "    # if conditions[품목명]['도매']:\n",
    "    #     filtered_도매 = 전국도매\n",
    "    #     for key, value in conditions[품목명]['도매'].items():\n",
    "    #         filtered_도매 = filtered_도매[filtered_도매[key].isin(value)]\n",
    "        \n",
    "    #     filtered_도매 = filtered_도매.add_prefix('도매_').rename(columns={'도매_시점': '시점'})\n",
    "    #     filtered_data = filtered_data.merge(filtered_도매, on='시점', how='left')\n",
    "\n",
    "    # 수치형 컬럼 처리\n",
    "    numeric_columns = filtered_data.select_dtypes(include=[np.number]).columns\n",
    "    # numeric_columns = [col for col in numeric_columns if col != '평년 평균가격(원)']\n",
    "    filtered_data = filtered_data[['시점'] + list(numeric_columns)]\n",
    "    filtered_data[numeric_columns] = filtered_data[numeric_columns].fillna(0)\n",
    "\n",
    "    # # 정규화 적용\n",
    "    # if scaler is None:\n",
    "    #     scaler = MinMaxScaler()\n",
    "    #     filtered_data[numeric_columns] = scaler.fit_transform(filtered_data[numeric_columns])\n",
    "    # else:\n",
    "    #     filtered_data[numeric_columns] = scaler.transform(filtered_data[numeric_columns])\n",
    "\n",
    "    return filtered_data, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품목: 깐마늘(국산)\n",
      "            시점  평년 평균가격(원)        평균가격(원)\n",
      "7200  201801상순         0.0  130666.666667\n",
      "7201  201801중순         0.0  130600.000000\n",
      "7202  201801하순         0.0  130600.000000\n",
      "7203  201802상순         0.0  134614.500000\n",
      "7204  201802중순         0.0  137100.000000\n",
      "...        ...         ...            ...\n",
      "7339  202111중순         0.0  167200.000000\n",
      "7340  202111하순         0.0  169100.000000\n",
      "7341  202112상순         0.0  169100.000000\n",
      "7342  202112중순         0.0  169100.000000\n",
      "7343  202112하순         0.0  168033.500000\n",
      "\n",
      "[144 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "product_list = ['건고추', '사과', '감자', '배', '깐마늘(국산)', '무', '상추', '배추', '양파', '대파']\n",
    "\n",
    "i = 4\n",
    "train_df, scaler = data_eda(\"./data/train/train.csv\", \n",
    "                            \"./data/train/meta/TRAIN_산지공판장_2018-2021.csv\", \n",
    "                            \"./data/train/meta/TRAIN_전국도매_2018-2021.csv\", \n",
    "                            product_list[i])\n",
    "print(\"품목:\", product_list[i])\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b293947e8d496a910736c85203f097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/431 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error happended in column:시점\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'시점'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msymmetric_difference\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, result_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3644\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3645\u001b[0m \u001b[38;5;124;03m    Compute the symmetric difference of two Index objects.\u001b[39;00m\n\u001b[0;32m   3646\u001b[0m \n\u001b[0;32m   3647\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   3648\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   3649\u001b[0m \u001b[38;5;124;03m    other : Index or array-like\u001b[39;00m\n\u001b[0;32m   3650\u001b[0m \u001b[38;5;124;03m    result_name : str\u001b[39;00m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;124;03m    sort : False or None, default None\u001b[39;00m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;124;03m        Whether to sort the resulting index. By default, the\u001b[39;00m\n\u001b[1;32m-> 3653\u001b[0m \u001b[38;5;124;03m        values are attempted to be sorted, but any TypeError from\u001b[39;00m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;124;03m        incomparable elements is caught by pandas.\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \n\u001b[0;32m   3656\u001b[0m \u001b[38;5;124;03m        * None : Attempt to sort the result, but catch any TypeErrors\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m \u001b[38;5;124;03m          from comparing incomparable elements.\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m \u001b[38;5;124;03m        * False : Do not sort the result.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m \n\u001b[0;32m   3660\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   3661\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   3662\u001b[0m \u001b[38;5;124;03m    symmetric_difference : Index\u001b[39;00m\n\u001b[0;32m   3663\u001b[0m \n\u001b[0;32m   3664\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[0;32m   3665\u001b[0m \u001b[38;5;124;03m    -----\u001b[39;00m\n\u001b[0;32m   3666\u001b[0m \u001b[38;5;124;03m    ``symmetric_difference`` contains elements that appear in either\u001b[39;00m\n\u001b[0;32m   3667\u001b[0m \u001b[38;5;124;03m    ``idx1`` or ``idx2`` but not both. Equivalent to the Index created by\u001b[39;00m\n\u001b[0;32m   3668\u001b[0m \u001b[38;5;124;03m    ``idx1.difference(idx2) | idx2.difference(idx1)`` with duplicates\u001b[39;00m\n\u001b[0;32m   3669\u001b[0m \u001b[38;5;124;03m    dropped.\u001b[39;00m\n\u001b[0;32m   3670\u001b[0m \n\u001b[0;32m   3671\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[0;32m   3672\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   3673\u001b[0m \u001b[38;5;124;03m    >>> idx1 = pd.Index([1, 2, 3, 4])\u001b[39;00m\n\u001b[0;32m   3674\u001b[0m \u001b[38;5;124;03m    >>> idx2 = pd.Index([2, 3, 4, 5])\u001b[39;00m\n\u001b[0;32m   3675\u001b[0m \u001b[38;5;124;03m    >>> idx1.symmetric_difference(idx2)\u001b[39;00m\n\u001b[0;32m   3676\u001b[0m \u001b[38;5;124;03m    Int64Index([1, 5], dtype='int64')\u001b[39;00m\n\u001b[0;32m   3677\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sort_keyword(sort)\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '시점'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 12\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(train_df))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# train_df_col = train_df.select_dtypes(include=[np.number]).columns\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# print(train_df_col)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# filter_data = [col for col in train_df_col if col != '시점']\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# print(filter_data)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# print(df)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mdataprep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\dataprep\\eda\\create_report\\__init__.py:68\u001b[0m, in \u001b[0;36mcreate_report\u001b[1;34m(df, config, display, title, mode, progress)\u001b[0m\n\u001b[0;32m     63\u001b[0m _suppress_warnings()\n\u001b[0;32m     64\u001b[0m cfg \u001b[38;5;241m=\u001b[39m Config\u001b[38;5;241m.\u001b[39mfrom_dict(display, config)\n\u001b[0;32m     65\u001b[0m context \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresources\u001b[39m\u001b[38;5;124m\"\u001b[39m: INLINE\u001b[38;5;241m.\u001b[39mrender(),\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: title,\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponents\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mformat_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     69\u001b[0m }\n\u001b[0;32m     70\u001b[0m template_base \u001b[38;5;241m=\u001b[39m ENV_LOADER\u001b[38;5;241m.\u001b[39mget_template(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m report \u001b[38;5;241m=\u001b[39m template_base\u001b[38;5;241m.\u001b[39mrender(context\u001b[38;5;241m=\u001b[39mcontext)\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\dataprep\\eda\\create_report\\formatter.py:78\u001b[0m, in \u001b[0;36mformat_report\u001b[1;34m(df, cfg, mode, progress)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbasic\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     77\u001b[0m     edaframe \u001b[38;5;241m=\u001b[39m EDAFrame(df)\n\u001b[1;32m---> 78\u001b[0m     comps \u001b[38;5;241m=\u001b[39m \u001b[43mformat_basic\u001b[49m\u001b[43m(\u001b[49m\u001b[43medaframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# elif mode == \"full\":\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m#     comps = format_full(df)\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# elif mode == \"minimal\":\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m#     comps = format_mini(df)\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\dataprep\\eda\\create_report\\formatter.py:291\u001b[0m, in \u001b[0;36mformat_basic\u001b[1;34m(df, cfg)\u001b[0m\n\u001b[0;32m    288\u001b[0m     (data,) \u001b[38;5;241m=\u001b[39m dask\u001b[38;5;241m.\u001b[39mcompute(data)\n\u001b[0;32m    290\u001b[0m res_overview \u001b[38;5;241m=\u001b[39m _format_overview(data, cfg)\n\u001b[1;32m--> 291\u001b[0m res_variables \u001b[38;5;241m=\u001b[39m \u001b[43m_format_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m res_interaction \u001b[38;5;241m=\u001b[39m _format_interaction(data, cfg)\n\u001b[0;32m    293\u001b[0m res_correlations \u001b[38;5;241m=\u001b[39m _format_correlation(data, cfg)\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\dataprep\\eda\\create_report\\formatter.py:120\u001b[0m, in \u001b[0;36m_format_variables\u001b[1;34m(df, cfg, data)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe type of column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is unknown: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(dtp)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 120\u001b[0m rndrd \u001b[38;5;241m=\u001b[39m \u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitmdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m layout \u001b[38;5;241m=\u001b[39m rndrd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    122\u001b[0m figs_var: List[Figure] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\dataprep\\eda\\distribution\\render.py:2473\u001b[0m, in \u001b[0;36mrender\u001b[1;34m(itmdt, cfg)\u001b[0m\n\u001b[0;32m   2471\u001b[0m     visual_elem \u001b[38;5;241m=\u001b[39m render_distribution_grid(itmdt, cfg)\n\u001b[0;32m   2472\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m itmdt\u001b[38;5;241m.\u001b[39mvisual_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_column\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2473\u001b[0m     visual_elem \u001b[38;5;241m=\u001b[39m \u001b[43mrender_cat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitmdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2474\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m itmdt\u001b[38;5;241m.\u001b[39mvisual_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeography_column\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2475\u001b[0m     visual_elem \u001b[38;5;241m=\u001b[39m render_geo(itmdt, cfg)\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\dataprep\\eda\\distribution\\render.py:1573\u001b[0m, in \u001b[0;36mrender_cat\u001b[1;34m(itmdt, cfg)\u001b[0m\n\u001b[0;32m   1567\u001b[0m     stats, len_stats, letter_stats \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1568\u001b[0m         data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1569\u001b[0m         data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1570\u001b[0m         data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mletter_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1571\u001b[0m     )\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mbar\u001b[38;5;241m.\u001b[39menable:\n\u001b[1;32m-> 1573\u001b[0m     fig \u001b[38;5;241m=\u001b[39m \u001b[43mbar_viz\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnuniq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnrows\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_width_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_height_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1580\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1583\u001b[0m     tabs\u001b[38;5;241m.\u001b[39mappend(Panel(child\u001b[38;5;241m=\u001b[39mrow(fig), title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBar Chart\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1584\u001b[0m     htgs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBar Chart\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mbar\u001b[38;5;241m.\u001b[39mhow_to_guide(plot_height, plot_width)\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\dataprep\\eda\\distribution\\render.py:223\u001b[0m, in \u001b[0;36mbar_viz\u001b[1;34m(df, ttl_grps, nrows, col, plot_width, plot_height, show_yticks, bar_cfg)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03mRender a bar chart\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# pylint: disable=too-many-arguments\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpct\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m/\u001b[39m nrows \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m    224\u001b[0m df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mindex]\n\u001b[0;32m    226\u001b[0m tooltips \u001b[38;5;241m=\u001b[39m [(col, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@index\u001b[39m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@pct\u001b[39m\u001b[38;5;132;01m{0.2f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m check_deprecated_indexers(key)\n\u001b[0;32m   3760\u001b[0m key \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mitem_from_zerodim(key)\n\u001b[1;32m-> 3761\u001b[0m key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   3763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3764\u001b[0m     \u001b[38;5;66;03m# is_iterator to exclude generator e.g. test_getitem_listlike\u001b[39;00m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;66;03m# shortcut if the key is in columns\u001b[39;00m\n\u001b[0;32m   3766\u001b[0m     is_mi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex)\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msymmetric_difference\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, result_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3644\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3645\u001b[0m \u001b[38;5;124;03m    Compute the symmetric difference of two Index objects.\u001b[39;00m\n\u001b[0;32m   3646\u001b[0m \n\u001b[0;32m   3647\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   3648\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   3649\u001b[0m \u001b[38;5;124;03m    other : Index or array-like\u001b[39;00m\n\u001b[0;32m   3650\u001b[0m \u001b[38;5;124;03m    result_name : str\u001b[39;00m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;124;03m    sort : False or None, default None\u001b[39;00m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;124;03m        Whether to sort the resulting index. By default, the\u001b[39;00m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;124;03m        values are attempted to be sorted, but any TypeError from\u001b[39;00m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;124;03m        incomparable elements is caught by pandas.\u001b[39;00m\n\u001b[1;32m-> 3655\u001b[0m \n\u001b[0;32m   3656\u001b[0m \u001b[38;5;124;03m        * None : Attempt to sort the result, but catch any TypeErrors\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m \u001b[38;5;124;03m          from comparing incomparable elements.\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m \u001b[38;5;124;03m        * False : Do not sort the result.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m \n\u001b[0;32m   3660\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   3661\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   3662\u001b[0m \u001b[38;5;124;03m    symmetric_difference : Index\u001b[39;00m\n\u001b[0;32m   3663\u001b[0m \n\u001b[0;32m   3664\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[0;32m   3665\u001b[0m \u001b[38;5;124;03m    -----\u001b[39;00m\n\u001b[0;32m   3666\u001b[0m \u001b[38;5;124;03m    ``symmetric_difference`` contains elements that appear in either\u001b[39;00m\n\u001b[0;32m   3667\u001b[0m \u001b[38;5;124;03m    ``idx1`` or ``idx2`` but not both. Equivalent to the Index created by\u001b[39;00m\n\u001b[0;32m   3668\u001b[0m \u001b[38;5;124;03m    ``idx1.difference(idx2) | idx2.difference(idx1)`` with duplicates\u001b[39;00m\n\u001b[0;32m   3669\u001b[0m \u001b[38;5;124;03m    dropped.\u001b[39;00m\n\u001b[0;32m   3670\u001b[0m \n\u001b[0;32m   3671\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[0;32m   3672\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   3673\u001b[0m \u001b[38;5;124;03m    >>> idx1 = pd.Index([1, 2, 3, 4])\u001b[39;00m\n\u001b[0;32m   3674\u001b[0m \u001b[38;5;124;03m    >>> idx2 = pd.Index([2, 3, 4, 5])\u001b[39;00m\n\u001b[0;32m   3675\u001b[0m \u001b[38;5;124;03m    >>> idx1.symmetric_difference(idx2)\u001b[39;00m\n\u001b[0;32m   3676\u001b[0m \u001b[38;5;124;03m    Int64Index([1, 5], dtype='int64')\u001b[39;00m\n\u001b[0;32m   3677\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sort_keyword(sort)\n\u001b[0;32m   3679\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_can_do_setop(other)\n",
      "\u001b[1;31mKeyError\u001b[0m: '시점'"
     ]
    }
   ],
   "source": [
    "import dataprep\n",
    "import dataprep.eda\n",
    "import pandas as pd\n",
    "\n",
    "print(type(train_df))\n",
    "# train_df_col = train_df.select_dtypes(include=[np.number]).columns\n",
    "# print(train_df_col)\n",
    "# filter_data = [col for col in train_df_col if col != '시점']\n",
    "# print(filter_data)\n",
    "# print(df)\n",
    "\n",
    "dataprep.eda.create_report(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>시점</th>\n",
       "      <th>평년 평균가격(원)</th>\n",
       "      <th>평균가격(원)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7200</th>\n",
       "      <td>201801상순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130666.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7201</th>\n",
       "      <td>201801중순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7202</th>\n",
       "      <td>201801하순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7203</th>\n",
       "      <td>201802상순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134614.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7204</th>\n",
       "      <td>201802중순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7339</th>\n",
       "      <td>202111중순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7340</th>\n",
       "      <td>202111하순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7341</th>\n",
       "      <td>202112상순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7342</th>\n",
       "      <td>202112중순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7343</th>\n",
       "      <td>202112하순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168033.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            시점  평년 평균가격(원)        평균가격(원)\n",
       "7200  201801상순         0.0  130666.666667\n",
       "7201  201801중순         0.0  130600.000000\n",
       "7202  201801하순         0.0  130600.000000\n",
       "7203  201802상순         0.0  134614.500000\n",
       "7204  201802중순         0.0  137100.000000\n",
       "...        ...         ...            ...\n",
       "7339  202111중순         0.0  167200.000000\n",
       "7340  202111하순         0.0  169100.000000\n",
       "7341  202112상순         0.0  169100.000000\n",
       "7342  202112중순         0.0  169100.000000\n",
       "7343  202112하순         0.0  168033.500000\n",
       "\n",
       "[144 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>평년 평균가격(원)</th>\n",
       "      <th>평균가격(원)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7200</th>\n",
       "      <td>201801상순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130666.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7201</th>\n",
       "      <td>201801중순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7202</th>\n",
       "      <td>201801하순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7203</th>\n",
       "      <td>201802상순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134614.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7204</th>\n",
       "      <td>201802중순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7339</th>\n",
       "      <td>202111중순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7340</th>\n",
       "      <td>202111하순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7341</th>\n",
       "      <td>202112상순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7342</th>\n",
       "      <td>202112중순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7343</th>\n",
       "      <td>202112하순</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168033.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      datetime  평년 평균가격(원)        평균가격(원)\n",
       "7200  201801상순         0.0  130666.666667\n",
       "7201  201801중순         0.0  130600.000000\n",
       "7202  201801하순         0.0  130600.000000\n",
       "7203  201802상순         0.0  134614.500000\n",
       "7204  201802중순         0.0  137100.000000\n",
       "...        ...         ...            ...\n",
       "7339  202111중순         0.0  167200.000000\n",
       "7340  202111하순         0.0  169100.000000\n",
       "7341  202112상순         0.0  169100.000000\n",
       "7342  202112중순         0.0  169100.000000\n",
       "7343  202112하순         0.0  168033.500000\n",
       "\n",
       "[144 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_data\n",
    "df = df.rename(columns={'시점':'datetime'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba4f41d9f254903b8c013446ada7373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/431 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error happended in column:datetime\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msymmetric_difference\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, result_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3644\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3645\u001b[0m \u001b[38;5;124;03m    Compute the symmetric difference of two Index objects.\u001b[39;00m\n\u001b[0;32m   3646\u001b[0m \n\u001b[0;32m   3647\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   3648\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   3649\u001b[0m \u001b[38;5;124;03m    other : Index or array-like\u001b[39;00m\n\u001b[0;32m   3650\u001b[0m \u001b[38;5;124;03m    result_name : str\u001b[39;00m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;124;03m    sort : False or None, default None\u001b[39;00m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;124;03m        Whether to sort the resulting index. By default, the\u001b[39;00m\n\u001b[1;32m-> 3653\u001b[0m \u001b[38;5;124;03m        values are attempted to be sorted, but any TypeError from\u001b[39;00m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;124;03m        incomparable elements is caught by pandas.\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \n\u001b[0;32m   3656\u001b[0m \u001b[38;5;124;03m        * None : Attempt to sort the result, but catch any TypeErrors\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m \u001b[38;5;124;03m          from comparing incomparable elements.\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m \u001b[38;5;124;03m        * False : Do not sort the result.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m \n\u001b[0;32m   3660\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   3661\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   3662\u001b[0m \u001b[38;5;124;03m    symmetric_difference : Index\u001b[39;00m\n\u001b[0;32m   3663\u001b[0m \n\u001b[0;32m   3664\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[0;32m   3665\u001b[0m \u001b[38;5;124;03m    -----\u001b[39;00m\n\u001b[0;32m   3666\u001b[0m \u001b[38;5;124;03m    ``symmetric_difference`` contains elements that appear in either\u001b[39;00m\n\u001b[0;32m   3667\u001b[0m \u001b[38;5;124;03m    ``idx1`` or ``idx2`` but not both. Equivalent to the Index created by\u001b[39;00m\n\u001b[0;32m   3668\u001b[0m \u001b[38;5;124;03m    ``idx1.difference(idx2) | idx2.difference(idx1)`` with duplicates\u001b[39;00m\n\u001b[0;32m   3669\u001b[0m \u001b[38;5;124;03m    dropped.\u001b[39;00m\n\u001b[0;32m   3670\u001b[0m \n\u001b[0;32m   3671\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[0;32m   3672\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   3673\u001b[0m \u001b[38;5;124;03m    >>> idx1 = pd.Index([1, 2, 3, 4])\u001b[39;00m\n\u001b[0;32m   3674\u001b[0m \u001b[38;5;124;03m    >>> idx2 = pd.Index([2, 3, 4, 5])\u001b[39;00m\n\u001b[0;32m   3675\u001b[0m \u001b[38;5;124;03m    >>> idx1.symmetric_difference(idx2)\u001b[39;00m\n\u001b[0;32m   3676\u001b[0m \u001b[38;5;124;03m    Int64Index([1, 5], dtype='int64')\u001b[39;00m\n\u001b[0;32m   3677\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sort_keyword(sort)\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'datetime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdataprep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\dataprep\\eda\\create_report\\__init__.py:68\u001b[0m, in \u001b[0;36mcreate_report\u001b[1;34m(df, config, display, title, mode, progress)\u001b[0m\n\u001b[0;32m     63\u001b[0m _suppress_warnings()\n\u001b[0;32m     64\u001b[0m cfg \u001b[38;5;241m=\u001b[39m Config\u001b[38;5;241m.\u001b[39mfrom_dict(display, config)\n\u001b[0;32m     65\u001b[0m context \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresources\u001b[39m\u001b[38;5;124m\"\u001b[39m: INLINE\u001b[38;5;241m.\u001b[39mrender(),\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: title,\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponents\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mformat_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     69\u001b[0m }\n\u001b[0;32m     70\u001b[0m template_base \u001b[38;5;241m=\u001b[39m ENV_LOADER\u001b[38;5;241m.\u001b[39mget_template(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m report \u001b[38;5;241m=\u001b[39m template_base\u001b[38;5;241m.\u001b[39mrender(context\u001b[38;5;241m=\u001b[39mcontext)\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\dataprep\\eda\\create_report\\formatter.py:78\u001b[0m, in \u001b[0;36mformat_report\u001b[1;34m(df, cfg, mode, progress)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbasic\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     77\u001b[0m     edaframe \u001b[38;5;241m=\u001b[39m EDAFrame(df)\n\u001b[1;32m---> 78\u001b[0m     comps \u001b[38;5;241m=\u001b[39m \u001b[43mformat_basic\u001b[49m\u001b[43m(\u001b[49m\u001b[43medaframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# elif mode == \"full\":\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m#     comps = format_full(df)\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# elif mode == \"minimal\":\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m#     comps = format_mini(df)\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\dataprep\\eda\\create_report\\formatter.py:291\u001b[0m, in \u001b[0;36mformat_basic\u001b[1;34m(df, cfg)\u001b[0m\n\u001b[0;32m    288\u001b[0m     (data,) \u001b[38;5;241m=\u001b[39m dask\u001b[38;5;241m.\u001b[39mcompute(data)\n\u001b[0;32m    290\u001b[0m res_overview \u001b[38;5;241m=\u001b[39m _format_overview(data, cfg)\n\u001b[1;32m--> 291\u001b[0m res_variables \u001b[38;5;241m=\u001b[39m \u001b[43m_format_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m res_interaction \u001b[38;5;241m=\u001b[39m _format_interaction(data, cfg)\n\u001b[0;32m    293\u001b[0m res_correlations \u001b[38;5;241m=\u001b[39m _format_correlation(data, cfg)\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\dataprep\\eda\\create_report\\formatter.py:120\u001b[0m, in \u001b[0;36m_format_variables\u001b[1;34m(df, cfg, data)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe type of column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is unknown: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(dtp)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 120\u001b[0m rndrd \u001b[38;5;241m=\u001b[39m \u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitmdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m layout \u001b[38;5;241m=\u001b[39m rndrd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    122\u001b[0m figs_var: List[Figure] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\dataprep\\eda\\distribution\\render.py:2473\u001b[0m, in \u001b[0;36mrender\u001b[1;34m(itmdt, cfg)\u001b[0m\n\u001b[0;32m   2471\u001b[0m     visual_elem \u001b[38;5;241m=\u001b[39m render_distribution_grid(itmdt, cfg)\n\u001b[0;32m   2472\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m itmdt\u001b[38;5;241m.\u001b[39mvisual_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_column\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2473\u001b[0m     visual_elem \u001b[38;5;241m=\u001b[39m \u001b[43mrender_cat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitmdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2474\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m itmdt\u001b[38;5;241m.\u001b[39mvisual_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeography_column\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2475\u001b[0m     visual_elem \u001b[38;5;241m=\u001b[39m render_geo(itmdt, cfg)\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\dataprep\\eda\\distribution\\render.py:1573\u001b[0m, in \u001b[0;36mrender_cat\u001b[1;34m(itmdt, cfg)\u001b[0m\n\u001b[0;32m   1567\u001b[0m     stats, len_stats, letter_stats \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1568\u001b[0m         data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1569\u001b[0m         data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1570\u001b[0m         data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mletter_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1571\u001b[0m     )\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mbar\u001b[38;5;241m.\u001b[39menable:\n\u001b[1;32m-> 1573\u001b[0m     fig \u001b[38;5;241m=\u001b[39m \u001b[43mbar_viz\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnuniq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnrows\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_width_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_height_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1580\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1583\u001b[0m     tabs\u001b[38;5;241m.\u001b[39mappend(Panel(child\u001b[38;5;241m=\u001b[39mrow(fig), title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBar Chart\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1584\u001b[0m     htgs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBar Chart\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mbar\u001b[38;5;241m.\u001b[39mhow_to_guide(plot_height, plot_width)\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\dataprep\\eda\\distribution\\render.py:223\u001b[0m, in \u001b[0;36mbar_viz\u001b[1;34m(df, ttl_grps, nrows, col, plot_width, plot_height, show_yticks, bar_cfg)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03mRender a bar chart\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# pylint: disable=too-many-arguments\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpct\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m/\u001b[39m nrows \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m    224\u001b[0m df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mstr\u001b[39m(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mindex]\n\u001b[0;32m    226\u001b[0m tooltips \u001b[38;5;241m=\u001b[39m [(col, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@index\u001b[39m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercent\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@pct\u001b[39m\u001b[38;5;132;01m{0.2f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m check_deprecated_indexers(key)\n\u001b[0;32m   3760\u001b[0m key \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mitem_from_zerodim(key)\n\u001b[1;32m-> 3761\u001b[0m key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   3763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3764\u001b[0m     \u001b[38;5;66;03m# is_iterator to exclude generator e.g. test_getitem_listlike\u001b[39;00m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;66;03m# shortcut if the key is in columns\u001b[39;00m\n\u001b[0;32m   3766\u001b[0m     is_mi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex)\n",
      "File \u001b[1;32mc:\\Users\\ty\\anaconda3\\envs\\dacon\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mget_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3643\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msymmetric_difference\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, result_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3644\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3645\u001b[0m \u001b[38;5;124;03m    Compute the symmetric difference of two Index objects.\u001b[39;00m\n\u001b[0;32m   3646\u001b[0m \n\u001b[0;32m   3647\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   3648\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m   3649\u001b[0m \u001b[38;5;124;03m    other : Index or array-like\u001b[39;00m\n\u001b[0;32m   3650\u001b[0m \u001b[38;5;124;03m    result_name : str\u001b[39;00m\n\u001b[0;32m   3651\u001b[0m \u001b[38;5;124;03m    sort : False or None, default None\u001b[39;00m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;124;03m        Whether to sort the resulting index. By default, the\u001b[39;00m\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;124;03m        values are attempted to be sorted, but any TypeError from\u001b[39;00m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;124;03m        incomparable elements is caught by pandas.\u001b[39;00m\n\u001b[1;32m-> 3655\u001b[0m \n\u001b[0;32m   3656\u001b[0m \u001b[38;5;124;03m        * None : Attempt to sort the result, but catch any TypeErrors\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m \u001b[38;5;124;03m          from comparing incomparable elements.\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m \u001b[38;5;124;03m        * False : Do not sort the result.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m \n\u001b[0;32m   3660\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m   3661\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m   3662\u001b[0m \u001b[38;5;124;03m    symmetric_difference : Index\u001b[39;00m\n\u001b[0;32m   3663\u001b[0m \n\u001b[0;32m   3664\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[0;32m   3665\u001b[0m \u001b[38;5;124;03m    -----\u001b[39;00m\n\u001b[0;32m   3666\u001b[0m \u001b[38;5;124;03m    ``symmetric_difference`` contains elements that appear in either\u001b[39;00m\n\u001b[0;32m   3667\u001b[0m \u001b[38;5;124;03m    ``idx1`` or ``idx2`` but not both. Equivalent to the Index created by\u001b[39;00m\n\u001b[0;32m   3668\u001b[0m \u001b[38;5;124;03m    ``idx1.difference(idx2) | idx2.difference(idx1)`` with duplicates\u001b[39;00m\n\u001b[0;32m   3669\u001b[0m \u001b[38;5;124;03m    dropped.\u001b[39;00m\n\u001b[0;32m   3670\u001b[0m \n\u001b[0;32m   3671\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[0;32m   3672\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m   3673\u001b[0m \u001b[38;5;124;03m    >>> idx1 = pd.Index([1, 2, 3, 4])\u001b[39;00m\n\u001b[0;32m   3674\u001b[0m \u001b[38;5;124;03m    >>> idx2 = pd.Index([2, 3, 4, 5])\u001b[39;00m\n\u001b[0;32m   3675\u001b[0m \u001b[38;5;124;03m    >>> idx1.symmetric_difference(idx2)\u001b[39;00m\n\u001b[0;32m   3676\u001b[0m \u001b[38;5;124;03m    Int64Index([1, 5], dtype='int64')\u001b[39;00m\n\u001b[0;32m   3677\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   3678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_sort_keyword(sort)\n\u001b[0;32m   3679\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_can_do_setop(other)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'datetime'"
     ]
    }
   ],
   "source": [
    "dataprep.eda.create_report(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
